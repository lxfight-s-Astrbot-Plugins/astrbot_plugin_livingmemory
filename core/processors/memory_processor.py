"""
记忆处理器 - 使用LLM将对话历史处理为结构化记忆
"""

import asyncio
import json
import random
import re
from datetime import datetime
from pathlib import Path
from typing import Any

from astrbot.api import logger

from ..models.conversation_models import Message


class MemoryProcessor:
    """
    记忆处理器

    使用LLM将对话历史转换为结构化记忆。
    支持私聊和群聊两种场景的不同处理策略。
    """

    def __init__(self, llm_provider, context=None):
        """
        初始化记忆处理器

        Args:
            llm_provider: LLM提供者实例(Provider类型)
            context: AstrBot上下文,用于获取人格管理器
        """
        self.llm_provider = llm_provider
        self.context = context

        # 加载提示词模板
        self._load_prompts()

    def _load_prompts(self) -> None:
        """从外部文件加载提示词模板"""
        prompt_dir = Path(__file__).parent.parent / "prompts"

        try:
            # 加载私聊提示词
            private_prompt_file = prompt_dir / "private_chat_prompt.txt"
            with open(private_prompt_file, encoding="utf-8") as f:
                self.private_chat_prompt = f.read()

            # 加载群聊提示词
            group_prompt_file = prompt_dir / "group_chat_prompt.txt"
            with open(group_prompt_file, encoding="utf-8") as f:
                self.group_chat_prompt = f.read()

            logger.info("[MemoryProcessor] 提示词模板加载成功")

        except Exception as e:
            logger.error(f"[MemoryProcessor] 加载提示词模板失败: {e}")
            # 使用简单的后备提示词（注意：使用 replace 替换，无需转义大括号）
            self.private_chat_prompt = """分析以下对话并生成JSON格式的记忆:
{conversation}

输出格式:
{"summary": "摘要", "topics": ["主题"], "key_facts": ["事实"], "sentiment": "neutral", "importance": 0.5}
"""
            self.group_chat_prompt = """分析以下群聊对话并生成JSON格式的记忆:
{conversation}

输出格式:
{"summary": "摘要", "topics": ["主题"], "key_facts": ["事实"], "participants": ["参与者"], "sentiment": "neutral", "importance": 0.5}
"""

    async def _build_system_prompt_with_persona(self, persona_id: str | None) -> str:
        """
        构建包含人格提示的 system_prompt

        Args:
            persona_id: 人格ID

        Returns:
            str: 包含人格提示的 system_prompt
        """
        base_prompt = "你是一个专业的对话分析助手,擅长提取对话中的关键信息。请严格按照JSON格式输出。"

        if not persona_id:
            logger.debug("[MemoryProcessor] 未指定人格ID，使用基础提示词")
            return base_prompt

        if not self.context:
            logger.debug("[MemoryProcessor] Context 未设置，使用基础提示词")
            return base_prompt

        try:
            persona_manager = getattr(self.context, "persona_manager", None)
            if not persona_manager:
                logger.warning(
                    "[MemoryProcessor] persona_manager 不可用，使用基础提示词"
                )
                return base_prompt

            persona = await persona_manager.get_persona(persona_id)
            if not persona:
                logger.warning(
                    f"[MemoryProcessor] 人格 '{persona_id}' 不存在，使用基础提示词"
                )
                return base_prompt

            if not persona.system_prompt:
                logger.debug(
                    f"[MemoryProcessor] 人格 '{persona_id}' 无 system_prompt，使用基础提示词"
                )
                return base_prompt

            persona_prompt = persona.system_prompt.strip()
            if not persona_prompt:
                logger.debug(
                    f"[MemoryProcessor] 人格 '{persona_id}' 的 system_prompt 为空，使用基础提示词"
                )
                return base_prompt

            logger.info(
                f"[MemoryProcessor] 成功加载人格 '{persona_id}' 的提示词 "
                f"(长度={len(persona_prompt)}字符)"
            )
            logger.debug(f"[MemoryProcessor] 人格提示词预览: {persona_prompt[:100]}...")

            enhanced_prompt = (
                f"{base_prompt}\n\n"
                f"## 人格设定\n"
                f"你需要以以下人格视角来总结对话记忆，确保记忆内容符合该人格的语言风格和行为特点：\n"
                f"{persona_prompt}\n\n"
                f"请在总结时体现这个人格的特点，包括语气、用词习惯和关注点。"
            )

            return enhanced_prompt

        except ValueError as e:
            logger.warning(f"[MemoryProcessor] 人格 '{persona_id}' 不存在: {e}")
            return base_prompt
        except Exception as e:
            logger.error(
                f"[MemoryProcessor] 获取人格提示词时发生错误: {e}", exc_info=True
            )
            return base_prompt

    async def _call_llm_with_retry(
        self, prompt: str, system_prompt: str, max_retries: int = 3
    ) -> str:
        """
        带指数退避的 LLM 调用

        Args:
            prompt: 提示词
            system_prompt: 系统提示词
            max_retries: 最大重试次数

        Returns:
            LLM 响应文本
        """
        last_error = None
        for attempt in range(max_retries):
            try:
                response = await self.llm_provider.text_chat(
                    prompt=prompt, system_prompt=system_prompt
                )
                return response.completion_text
            except Exception as e:
                last_error = e
                if attempt == max_retries - 1:
                    raise
                wait_time = (2**attempt) + random.uniform(0, 1)
                logger.warning(
                    f"[MemoryProcessor] LLM 调用失败，{wait_time:.1f}s 后重试 "
                    f"({attempt + 1}/{max_retries}): {e}"
                )
                await asyncio.sleep(wait_time)
        if last_error:
            raise last_error
        raise RuntimeError("LLM 调用失败，未捕获到具体异常")

    def _try_fix_json(self, text: str) -> str:
        """
        尝试修复损坏的 JSON 字符串

        Args:
            text: 可能损坏的 JSON 字符串

        Returns:
            修复后的 JSON 字符串
        """
        fixed = text.strip()

        # 移除 markdown 代码块标记
        if fixed.startswith("```json"):
            fixed = fixed[7:]
        elif fixed.startswith("```"):
            fixed = fixed[3:]
        if fixed.endswith("```"):
            fixed = fixed[:-3]
        fixed = fixed.strip()

        # 修复未闭合的字符串（截断的 JSON）
        open_quotes = fixed.count('"') - fixed.count('\\"')
        if open_quotes % 2 != 0:
            fixed += '"'

        # 修复未闭合的数组
        open_brackets = fixed.count("[") - fixed.count("]")
        if open_brackets > 0:
            fixed += "]" * open_brackets

        # 修复未闭合的对象
        open_braces = fixed.count("{") - fixed.count("}")
        if open_braces > 0:
            fixed += "}" * open_braces

        # 移除尾部逗号（JSON 不允许）
        fixed = re.sub(r",(\s*[}\]])", r"\1", fixed)

        # 修复常见的转义问题
        fixed = fixed.replace("\n", "\\n").replace("\r", "\\r").replace("\t", "\\t")

        return fixed

    async def process_conversation(
        self,
        messages: list[Message],
        is_group_chat: bool = False,
        save_original: bool = False,
        persona_id: str | None = None,
    ) -> tuple[str, dict[str, Any], float]:
        """
        处理对话历史,生成结构化记忆

        Args:
            messages: 消息列表(Message对象)
            is_group_chat: 是否为群聊
            save_original: 是否保存原始对话历史（默认False，只保存LLM生成的总结）
            persona_id: 人格ID,用于获取人格提示词

        Returns:
            tuple: (content, metadata, importance)
                - content: 格式化的记忆内容字符串
                - metadata: 包含结构化信息的字典
                - importance: 重要性评分(0-1)

        Raises:
            Exception: 处理失败时抛出异常
        """
        if not messages:
            raise ValueError("消息列表不能为空")

        # 1. 格式化对话历史
        conversation_text = self._format_conversation(messages)

        # 2. 选择合适的提示词模板
        # 使用 replace 而非 format，避免对话内容中的大括号导致解析错误
        if is_group_chat:
            prompt = self.group_chat_prompt.replace("{conversation}", conversation_text)
        else:
            prompt = self.private_chat_prompt.replace(
                "{conversation}", conversation_text
            )

        # 3. 调用LLM生成结构化记忆
        conversation_type = "群聊" if is_group_chat else "私聊"
        try:
            logger.info(
                f"[MemoryProcessor] 准备调用 LLM，对话类型={conversation_type}, 消息数={len(messages)}"
            )
            logger.debug(f"[MemoryProcessor] Prompt 模板长度={len(prompt)}")
            logger.debug(
                f"[MemoryProcessor] 发送给LLM的对话内容（前500字符）:\n{conversation_text[:500]}"
            )

            # 构建 system_prompt，嵌入人格提示
            system_prompt = await self._build_system_prompt_with_persona(persona_id)
            logger.debug(f"[MemoryProcessor] System Prompt: {system_prompt[:200]}...")

            llm_response_text = await self._call_llm_with_retry(
                prompt=prompt,
                system_prompt=system_prompt,
            )

            logger.info(
                f"[MemoryProcessor]  LLM 响应成功，响应长度={len(llm_response_text)}"
            )
            logger.debug(f"[MemoryProcessor] LLM 原始响应内容:\n{llm_response_text}")

            # 4. 解析LLM响应
            structured_data = self._parse_llm_response(llm_response_text, is_group_chat)

            # 5. 构建存储格式
            content, metadata = self._build_storage_format(
                conversation_text, structured_data, is_group_chat
            )

            importance = float(structured_data.get("importance", 0.5))

            logger.info(
                f"[MemoryProcessor]  成功生成结构化记忆: 摘要={structured_data.get('summary', '')[:50]}..., "
                f"主题={structured_data.get('topics', [])}, "
                f"重要性={importance}, 类型={conversation_type}"
            )
            logger.debug(
                f"[MemoryProcessor] 生成的记忆内容（前200字符）:\n{content[:200]}"
            )

            return content, metadata, importance

        except Exception as e:
            logger.error(f"[MemoryProcessor] 处理对话历史失败: {e}", exc_info=True)
            # 不再降级处理，直接向上抛出异常，由调用方处理重试逻辑
            raise

    def _format_conversation(self, messages: list[Message]) -> str:
        """
        格式化对话历史为文本

        Args:
            messages: 消息列表(Message对象)

        Returns:
            格式化后的对话文本
        """

        formatted_lines = []
        for i, msg in enumerate(messages):
            logger.debug(
                f"[_format_conversation] 消息#{i}: "
                f"sender_id={msg.sender_id}, sender_name={msg.sender_name}, "
                f"role={msg.role}, group_id={msg.group_id}"
            )

            if msg.group_id:
                # 群聊场景：使用Message对象的format_for_llm方法
                formatted = msg.format_for_llm(include_sender_name=True)
                formatted_lines.append(formatted["content"])
                logger.debug(
                    f"[_format_conversation] 消息#{i} 格式化结果(群聊): {formatted['content'][:100]}..."
                )
            else:
                # 私聊场景：也使用 [昵称 | ID: xxx | 时间] 格式
                time_str = datetime.fromtimestamp(msg.timestamp).strftime(
                    "%Y-%m-%d %H:%M:%S"
                )
                display_name = (
                    msg.sender_name if msg.sender_name else msg.sender_id or "未知"
                )
                is_bot = (
                    msg.metadata.get("is_bot_message", False) or msg.role == "assistant"
                )

                if is_bot:
                    sender_info = (
                        f"[Bot: {display_name} | ID: {msg.sender_id} | {time_str}]"
                    )
                else:
                    sender_info = f"[{display_name} | ID: {msg.sender_id} | {time_str}]"

                formatted_lines.append(f"{sender_info} {msg.content}")
                logger.debug(
                    f"[_format_conversation] 消息#{i} 格式化结果(私聊): {sender_info[:50]}..."
                )
        return "\n".join(formatted_lines)

    def _parse_llm_response(
        self, response_text: str, is_group_chat: bool
    ) -> dict[str, Any]:
        """
        解析LLM响应,提取JSON数据

        Args:
            response_text: LLM响应文本
            is_group_chat: 是否为群聊

        Returns:
            解析后的字典数据
        """
        logger.debug(f"[MemoryProcessor] 开始解析 LLM 响应，长度={len(response_text)}")

        try:
            # 尝试直接解析JSON
            # 先清理可能的markdown代码块标记
            cleaned_text = response_text.strip()
            logger.debug(
                f"[MemoryProcessor] 清理前的响应文本（前100字符）: {response_text[:100]}"
            )

            if cleaned_text.startswith("```json"):
                cleaned_text = cleaned_text[7:]
                logger.debug("[MemoryProcessor] 移除了 ```json 标记")
            if cleaned_text.startswith("```"):
                cleaned_text = cleaned_text[3:]
                logger.debug("[MemoryProcessor] 移除了 ``` 标记")
            if cleaned_text.endswith("```"):
                cleaned_text = cleaned_text[:-3]
                logger.debug("[MemoryProcessor] 移除了结尾 ``` 标记")
            cleaned_text = cleaned_text.strip()

            logger.debug(
                f"[MemoryProcessor] 清理后准备解析的 JSON（前500字符）:\n{cleaned_text[:500]}"
            )

            # 解析JSON
            data = json.loads(cleaned_text)

            # 类型检查：确保解析结果是 dict
            if not isinstance(data, dict):
                logger.warning(
                    f"[MemoryProcessor] JSON 解析结果不是 dict，类型为 {type(data).__name__}"
                )
                raise ValueError(f"期望 dict 类型，实际为 {type(data).__name__}")

            logger.info("[MemoryProcessor] JSON 解析成功")
            logger.debug(f"[MemoryProcessor] 解析得到的字段: {list(data.keys())}")

            # 验证必需字段 - 简化后的字段列表
            required_fields = [
                "summary",
                "topics",
                "key_facts",
                "sentiment",
                "importance",
            ]
            if is_group_chat:
                required_fields.append("participants")

            for field in required_fields:
                if field not in data:
                    logger.warning(
                        f"[MemoryProcessor] LLM 响应缺少字段: {field}, 使用默认值"
                    )
                    data[field] = self._get_default_value(field)

            # 数据类型校验和规范化
            data["summary"] = str(data.get("summary", ""))
            logger.debug(f"[MemoryProcessor] 提取 summary: {data['summary'][:100]}...")

            data["topics"] = self._ensure_list(data.get("topics", []))[:5]
            logger.debug(
                f"[MemoryProcessor] 提取 topics ({len(data['topics'])} 个): {data['topics']}"
            )

            data["key_facts"] = self._ensure_list(data.get("key_facts", []))[:5]
            logger.debug(
                f"[MemoryProcessor] 提取 key_facts ({len(data['key_facts'])} 个): {data['key_facts']}"
            )

            data["sentiment"] = self._validate_sentiment(
                data.get("sentiment", "neutral")
            )
            logger.debug(f"[MemoryProcessor] 提取 sentiment: {data['sentiment']}")

            data["importance"] = self._validate_importance(data.get("importance", 0.5))
            logger.debug(f"[MemoryProcessor] 提取 importance: {data['importance']}")

            if is_group_chat:
                data["participants"] = self._ensure_list(data.get("participants", []))
                logger.debug(
                    f"[MemoryProcessor] 提取 participants ({len(data['participants'])} 个): {data['participants']}"
                )

            return data

        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"[MemoryProcessor]  JSON 解析失败: {e}")
            logger.debug(
                f"[MemoryProcessor] 解析失败的内容（前200字符）: {response_text[:200]}"
            )

            # 尝试修复 JSON 后再解析
            logger.info("[MemoryProcessor] 尝试修复 JSON 后重新解析")
            try:
                fixed_text = self._try_fix_json(response_text)
                data = json.loads(fixed_text)
                if isinstance(data, dict):
                    logger.info("[MemoryProcessor] JSON 修复后解析成功")
                    return self._normalize_parsed_data(data, is_group_chat)
            except (json.JSONDecodeError, ValueError) as fix_err:
                logger.debug(f"[MemoryProcessor] JSON 修复后仍无法解析: {fix_err}")

            logger.info("[MemoryProcessor] 尝试使用正则表达式提取 JSON")
            # 尝试正则提取
            return self._extract_by_regex(response_text, is_group_chat)
        except Exception as e:
            logger.error(
                f"[MemoryProcessor]  解析 LLM 响应时发生异常: {e}", exc_info=True
            )
            logger.debug(
                f"[MemoryProcessor] 异常发生时的响应内容: {response_text[:200]}"
            )
            return self._get_default_structured_data(is_group_chat)

    def _extract_by_regex(self, text: str, is_group_chat: bool) -> dict[str, Any]:
        """
        使用正则表达式从文本中提取结构化数据(备用方案)

        Args:
            text: 响应文本
            is_group_chat: 是否为群聊

        Returns:
            提取的结构化数据
        """
        logger.debug("[MemoryProcessor] 开始使用正则表达式提取结构化数据")
        data = self._get_default_structured_data(is_group_chat)

        try:
            # 先尝试找到完整的 JSON 块
            json_matches = re.findall(
                r"\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}", text, re.DOTALL
            )
            logger.debug(
                f"[MemoryProcessor] 正则匹配到 {len(json_matches)} 个可能的 JSON 块"
            )

            for i, match in enumerate(json_matches):
                logger.debug(
                    f"[MemoryProcessor] JSON 块 #{i + 1} (前200字符): {match[:200]}..."
                )
                try:
                    # 尝试解析每个匹配的块
                    parsed = json.loads(match)
                    if "summary" in parsed:
                        logger.info(
                            f"[MemoryProcessor]  成功从第 {i + 1} 个 JSON 块中解析数据"
                        )
                        data = parsed
                        break
                except json.JSONDecodeError:
                    continue

            # 如果没有找到完整的 JSON，尝试单独提取字段
            if data == self._get_default_structured_data(is_group_chat):
                logger.debug("[MemoryProcessor] 未找到完整 JSON，尝试提取单独字段")

                # 提取summary
                summary_match = re.search(r'"summary"\s*:\s*"([^"]+)"', text)
                if summary_match:
                    data["summary"] = summary_match.group(1)
                    logger.debug(
                        f"[MemoryProcessor] 正则提取 summary: {data['summary'][:50]}..."
                    )

                # 提取importance
                importance_match = re.search(r'"importance"\s*:\s*([0-9.]+)', text)
                if importance_match:
                    data["importance"] = float(importance_match.group(1))
                    logger.debug(
                        f"[MemoryProcessor] 正则提取 importance: {data['importance']}"
                    )

                # 提取sentiment
                sentiment_match = re.search(r'"sentiment"\s*:\s*"(\w+)"', text)
                if sentiment_match:
                    data["sentiment"] = sentiment_match.group(1)
                    logger.debug(
                        f"[MemoryProcessor] 正则提取 sentiment: {data['sentiment']}"
                    )

                # 提取 topics 数组
                topics_match = re.search(r'"topics"\s*:\s*\[(.*?)\]', text, re.DOTALL)
                if topics_match:
                    topics_str = topics_match.group(1)
                    topics = re.findall(r'"([^"]+)"', topics_str)
                    data["topics"] = topics[:5]
                    logger.debug(f"[MemoryProcessor] 正则提取 topics: {data['topics']}")

                # 提取 key_facts 数组
                facts_match = re.search(r'"key_facts"\s*:\s*\[(.*?)\]', text, re.DOTALL)
                if facts_match:
                    facts_str = facts_match.group(1)
                    facts = re.findall(r'"([^"]+)"', facts_str)
                    data["key_facts"] = facts[:5]
                    logger.debug(
                        f"[MemoryProcessor] 正则提取 key_facts: {data['key_facts']}"
                    )

            logger.info(
                f"[MemoryProcessor] 正则提取完成，提取到的字段: {list(data.keys())}"
            )

        except Exception as e:
            logger.error(f"[MemoryProcessor]  正则提取失败: {e}", exc_info=True)

        return data

    def _build_storage_format(
        self,
        conversation_text: str,
        structured_data: dict[str, Any],
        is_group_chat: bool,
    ) -> tuple[str, dict[str, Any]]:
        """
        构建存储格式

        Args:
            conversation_text: 原始对话文本（已不再使用，保留参数以兼容旧代码）
            structured_data: 结构化数据
            is_group_chat: 是否为群聊

        Returns:
            (content, metadata) 元组
        """
        # content字段：只保留LLM生成的摘要（第一人称）
        summary = structured_data.get("summary", "")
        if summary:
            content = summary
        else:
            # 降级方案：如果没有摘要，使用简短的对话文本
            content = (
                conversation_text[:200] + "..."
                if len(conversation_text) > 200
                else conversation_text
            )

        # metadata字段:存储结构化信息
        # 注意：不要在这里设置 create_time 和 last_access_time
        # 这些字段会由 MemoryEngine.add_memory() 自动添加
        metadata = {
            "topics": structured_data.get("topics", []),
            "key_facts": structured_data.get("key_facts", []),
            "sentiment": structured_data.get("sentiment", "neutral"),
            "interaction_type": "group_chat" if is_group_chat else "private_chat",
        }

        if is_group_chat and "participants" in structured_data:
            metadata["participants"] = structured_data["participants"]

        return content, metadata

    def _normalize_parsed_data(self, data: dict, is_group_chat: bool) -> dict[str, Any]:
        """
        规范化解析后的数据（补充缺失字段、类型转换）

        Args:
            data: 解析后的原始字典
            is_group_chat: 是否为群聊

        Returns:
            规范化后的字典
        """
        required_fields = ["summary", "topics", "key_facts", "sentiment", "importance"]
        if is_group_chat:
            required_fields.append("participants")

        for field in required_fields:
            if field not in data:
                data[field] = self._get_default_value(field)

        data["summary"] = str(data.get("summary", ""))
        data["topics"] = self._ensure_list(data.get("topics", []))[:5]
        data["key_facts"] = self._ensure_list(data.get("key_facts", []))[:5]
        data["sentiment"] = self._validate_sentiment(data.get("sentiment", "neutral"))
        data["importance"] = self._validate_importance(data.get("importance", 0.5))

        if is_group_chat:
            data["participants"] = self._ensure_list(data.get("participants", []))

        return data

    def _ensure_list(self, value: Any) -> list[str]:
        """确保值是字符串列表"""
        if isinstance(value, list):
            return [str(item) for item in value if item]
        elif isinstance(value, str):
            return [value] if value else []
        else:
            return []

    def _validate_sentiment(self, sentiment: str) -> str:
        """验证情感值"""
        valid_sentiments = ["positive", "neutral", "negative"]
        sentiment = sentiment.lower()
        return sentiment if sentiment in valid_sentiments else "neutral"

    def _validate_importance(self, importance: Any) -> float:
        """验证重要性评分"""
        try:
            score = float(importance)
            return max(0.0, min(1.0, score))  # 限制在0-1之间
        except (ValueError, TypeError):
            return 0.5

    def _get_default_value(self, field: str) -> Any:
        """获取字段的默认值"""
        defaults = {
            "summary": "",
            "topics": [],
            "key_facts": [],
            "participants": [],
            "sentiment": "neutral",
            "importance": 0.5,
        }
        return defaults.get(field, "")

    def _get_default_structured_data(self, is_group_chat: bool) -> dict[str, Any]:
        """获取默认的结构化数据"""
        data = {
            "summary": "对话记录",
            "topics": [],
            "key_facts": [],
            "sentiment": "neutral",
            "importance": 0.5,
        }
        if is_group_chat:
            data["participants"] = []
        return data
