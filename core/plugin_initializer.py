"""
æ’ä»¶åˆå§‹åŒ–å™¨
è´Ÿè´£æ’ä»¶çš„åˆå§‹åŒ–é€»è¾‘
"""

import asyncio
import os
import time

from astrbot.api import logger
from astrbot.api.star import Context
from astrbot.core.db.vec_db.faiss_impl.vec_db import FaissVecDB
from astrbot.core.provider.provider import EmbeddingProvider, Provider

from ..storage.conversation_store import ConversationStore
from ..storage.db_migration import DBMigration
from .base.config_manager import ConfigManager
from .base.exceptions import InitializationError, ProviderNotReadyError
from .managers.conversation_manager import ConversationManager
from .managers.memory_engine import MemoryEngine
from .processors.memory_processor import MemoryProcessor
from .schedulers.decay_scheduler import DecayScheduler
from .validators.index_validator import IndexValidator


class PluginInitializer:
    """æ’ä»¶åˆå§‹åŒ–å™¨"""

    def __init__(self, context: Context, config_manager: ConfigManager, data_dir: str):
        """
        åˆå§‹åŒ–æ’ä»¶åˆå§‹åŒ–å™¨

        Args:
            context: AstrBotä¸Šä¸‹æ–‡
            config_manager: é…ç½®ç®¡ç†å™¨
            data_dir: æ’ä»¶æ•°æ®ç›®å½•è·¯å¾„
        """
        self.context = context
        self.config_manager = config_manager
        self.data_dir = data_dir

        # ç»„ä»¶å®ä¾‹
        self.embedding_provider: EmbeddingProvider | None = None
        self.llm_provider: Provider | None = None
        self.db: FaissVecDB | None = None
        self.memory_engine: MemoryEngine | None = None
        self.memory_processor: MemoryProcessor | None = None
        self.db_migration: DBMigration | None = None
        self.conversation_manager: ConversationManager | None = None
        self.index_validator: IndexValidator | None = None
        self.decay_scheduler: DecayScheduler | None = None

        # åˆå§‹åŒ–çŠ¶æ€
        self._initialization_complete = False
        self._initialization_lock = asyncio.Lock()
        self._initialization_failed = False
        self._initialization_error: str | None = None
        self._providers_ready = False
        self._provider_check_attempts = 0
        self._max_provider_attempts = 60
        self._retry_task: asyncio.Task | None = None

    async def initialize(self) -> bool:
        """
        æ‰§è¡Œåˆå§‹åŒ–

        Returns:
            bool: æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        """
        async with self._initialization_lock:
            if self._initialization_complete or self._initialization_failed:
                return self._initialization_complete

        logger.info("LivingMemory æ’ä»¶å¼€å§‹åå°åˆå§‹åŒ–...")

        try:
            # 1. ç­‰å¾… Provider å°±ç»ª
            if not await self._wait_for_providers_non_blocking():
                missing = []
                if not self.embedding_provider:
                    missing.append("Embedding Providerï¼ˆè¯·åœ¨ AstrBot ä¸­é…ç½®å‘é‡åµŒå…¥æ¨¡å‹ï¼‰")
                if not self.llm_provider:
                    missing.append("LLM Providerï¼ˆè¯·åœ¨ AstrBot ä¸­é…ç½®è¯­è¨€æ¨¡å‹ï¼‰")
                logger.warning(
                    f"ä»¥ä¸‹ Provider æš‚æ—¶ä¸å¯ç”¨ï¼Œå°†åœ¨åå°ç»§ç»­å°è¯•: {', '.join(missing)}"
                )
                self._start_retry_task_if_needed()
                return False

            # 2. Provider å°±ç»ªï¼Œç»§ç»­å®Œæ•´åˆå§‹åŒ–
            await self._complete_initialization()
            return True

        except Exception as e:
            logger.error(f"LivingMemory æ’ä»¶åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            self._initialization_failed = True
            self._initialization_error = str(e)
            return False

    def _start_retry_task_if_needed(self) -> None:
        """å¯åŠ¨åå°é‡è¯•ä»»åŠ¡ï¼ˆé¿å…é‡å¤å¯åŠ¨ï¼‰"""
        if self._retry_task and not self._retry_task.done():
            return

        self._retry_task = asyncio.create_task(self._retry_initialization())
        self._retry_task.add_done_callback(self._on_retry_task_done)

    def _on_retry_task_done(self, task: asyncio.Task) -> None:
        """é‡è¯•ä»»åŠ¡å®Œæˆå›è°ƒï¼Œå›æ”¶çŠ¶æ€å¹¶è®°å½•å¼‚å¸¸"""
        self._retry_task = None
        if task.cancelled():
            return
        try:
            exc = task.exception()
            if exc:
                logger.error(f"Provider é‡è¯•ä»»åŠ¡å¼‚å¸¸é€€å‡º: {exc}")
        except Exception:
            # é˜²å¾¡æ€§å¤„ç†ï¼šè¯»å– task.exception() æ—¶ä¸åº”é˜»æ–­ä¸»æµç¨‹
            pass

    async def _wait_for_providers_non_blocking(self, max_wait: float = 5.0) -> bool:
        """éé˜»å¡åœ°æ£€æŸ¥ Provider æ˜¯å¦å¯ç”¨"""
        start_time = time.time()
        check_interval = 1.0

        while time.time() - start_time < max_wait:
            self._initialize_providers(silent=True)

            if self.embedding_provider and self.llm_provider:
                logger.info("âœ… Provider å·²å°±ç»ª")
                self._providers_ready = True
                return True

            await asyncio.sleep(check_interval)
            self._provider_check_attempts += 1

        logger.debug(
            f"Provider åœ¨ {max_wait}ç§’å†…æœªå°±ç»ªï¼ˆå·²å°è¯• {self._provider_check_attempts} æ¬¡ï¼‰"
            f"ï¼šembedding={'âœ…' if self.embedding_provider else 'âŒ'}, "
            f"llm={'âœ…' if self.llm_provider else 'âŒ'}"
        )
        return False

    async def _retry_initialization(self):
        """åå°é‡è¯•åˆå§‹åŒ–ä»»åŠ¡ï¼ˆæŒ‡æ•°é€€é¿ç­–ç•¥ï¼‰"""
        base_interval = 2.0
        max_interval = 30.0
        current_interval = base_interval
        log_interval = 5

        while (
            not self._initialization_complete
            and not self._initialization_failed
            and self._provider_check_attempts < self._max_provider_attempts
        ):
            await asyncio.sleep(current_interval)

            self._initialize_providers(silent=True)
            self._provider_check_attempts += 1

            if self._provider_check_attempts % log_interval == 0:
                missing = []
                if not self.embedding_provider:
                    missing.append("Embedding Provider")
                if not self.llm_provider:
                    missing.append("LLM Provider")
                logger.info(
                    f"â³ ç­‰å¾… Provider å°±ç»ªä¸­ï¼ˆæœªå°±ç»ª: {', '.join(missing)}ï¼‰..."
                    f"ï¼ˆå·²å°è¯• {self._provider_check_attempts}/{self._max_provider_attempts} æ¬¡ï¼Œ"
                    f"ä¸‹æ¬¡é‡è¯•é—´éš” {current_interval:.1f}sï¼‰"
                )

            if self.embedding_provider and self.llm_provider:
                logger.info(
                    f"âœ… Provider åœ¨ç¬¬ {self._provider_check_attempts} æ¬¡å°è¯•åå°±ç»ªï¼Œç»§ç»­åˆå§‹åŒ–..."
                )
                self._providers_ready = True

                try:
                    async with self._initialization_lock:
                        if not self._initialization_complete:
                            await self._complete_initialization()
                except Exception as e:
                    logger.error(f"é‡è¯•åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
                    self._initialization_failed = True
                    self._initialization_error = str(e)
                break

            # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤§30ç§’
            current_interval = min(current_interval * 1.5, max_interval)

        if not self._initialization_complete and not self._initialization_failed:
            missing = []
            if not self.embedding_provider:
                missing.append("Embedding Providerï¼ˆè¯·é…ç½®å‘é‡åµŒå…¥æ¨¡å‹ï¼‰")
            if not self.llm_provider:
                missing.append("LLM Providerï¼ˆè¯·é…ç½®è¯­è¨€æ¨¡å‹ï¼‰")
            logger.error(
                f"âŒ ä»¥ä¸‹ Provider åœ¨ {self._provider_check_attempts} æ¬¡å°è¯•åä»æœªå°±ç»ªï¼Œåˆå§‹åŒ–å¤±è´¥: "
                f"{', '.join(missing) if missing else 'æœªçŸ¥'}"
            )
            self._initialization_failed = True
            self._initialization_error = "Provider åˆå§‹åŒ–è¶…æ—¶"

    def _initialize_providers(self, silent: bool = False):
        """åˆå§‹åŒ– Embedding å’Œ LLM provider"""
        # åˆå§‹åŒ– Embedding Provider
        emb_id = self.config_manager.get("provider_settings.embedding_provider_id")
        if emb_id:
            provider = self.context.get_provider_by_id(emb_id)
            if provider and isinstance(provider, EmbeddingProvider):
                self.embedding_provider = provider
                if not silent:
                    logger.info(f"æˆåŠŸä»é…ç½®åŠ è½½ Embedding Provider: {emb_id}")
            elif provider and not silent:
                logger.warning(f"Provider {emb_id} ä¸æ˜¯ EmbeddingProvider ç±»å‹")

        if not self.embedding_provider:
            embedding_providers = self.context.get_all_embedding_providers()
            if embedding_providers:
                self.embedding_provider = embedding_providers[0]
                if not silent:
                    provider_id = getattr(
                        self.embedding_provider.provider_config,
                        "id",
                        self.embedding_provider.provider_config.get("id", "unknown"),
                    )
                    logger.info(f"æœªæŒ‡å®š Embedding Providerï¼Œä½¿ç”¨é»˜è®¤çš„: {provider_id}")
            else:
                self.embedding_provider = None
                if not silent:
                    logger.debug("æ²¡æœ‰å¯ç”¨çš„ Embedding Provider")

        # åˆå§‹åŒ– LLM Provider
        self.llm_provider = None
        llm_id = self.config_manager.get("provider_settings.llm_provider_id")
        if llm_id:
            provider = self.context.get_provider_by_id(llm_id)
            if provider and isinstance(provider, Provider):
                self.llm_provider = provider
                if not silent:
                    logger.info(f"æˆåŠŸä»é…ç½®åŠ è½½ LLM Provider: {llm_id}")
            elif provider and not silent:
                logger.warning(
                    f"Provider {llm_id} ä¸æ˜¯èŠå¤© Provider ç±»å‹ï¼Œå·²å¿½ç•¥è¯¥é…ç½®ã€‚"
                )

        if not self.llm_provider:
            try:
                default_provider = self.context.get_using_provider()
                if default_provider and not isinstance(default_provider, Provider):
                    if not silent:
                        logger.warning(
                            "AstrBot é»˜è®¤ Provider ç±»å‹ä¸æ­£ç¡®ï¼ŒæœŸæœ›èŠå¤© Providerã€‚"
                        )
                    self.llm_provider = None
                else:
                    self.llm_provider = default_provider
                if not silent and self.llm_provider:
                    logger.info("ä½¿ç”¨ AstrBot å½“å‰é»˜è®¤çš„ LLM Providerã€‚")
            except (ValueError, Exception) as e:
                if not silent:
                    logger.debug(f"è·å–é»˜è®¤ LLM Provider å¤±è´¥: {e}")
                self.llm_provider = None

    async def _complete_initialization(self):
        """å®Œæˆå®Œæ•´çš„åˆå§‹åŒ–æµç¨‹"""
        if self._initialization_complete:
            return

        logger.info("å¼€å§‹å®Œæ•´åˆå§‹åŒ–æµç¨‹...")

        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            db_path = os.path.join(self.data_dir, "livingmemory.db")
            index_path = os.path.join(self.data_dir, "livingmemory.index")

            if not self.embedding_provider:
                raise ProviderNotReadyError("Embedding Provider æœªåˆå§‹åŒ–")
            if not self.llm_provider or not isinstance(self.llm_provider, Provider):
                raise ProviderNotReadyError("LLM Provider æœªåˆå§‹åŒ–æˆ–ç±»å‹ä¸æ­£ç¡®")

            # æ£€æŸ¥ç´¢å¼•æ–‡ä»¶ç»´åº¦ä¸å½“å‰ embedding provider ç»´åº¦æ˜¯å¦ä¸€è‡´
            await self._check_and_fix_dimension_mismatch(index_path)

            self.db = FaissVecDB(db_path, index_path, self.embedding_provider)
            await self.db.initialize()
            logger.info(f"æ•°æ®åº“å·²åˆå§‹åŒ–ã€‚æ•°æ®ç›®å½•: {self.data_dir}")

            # åˆå§‹åŒ–æ•°æ®åº“è¿ç§»ç®¡ç†å™¨
            self.db_migration = DBMigration(db_path)

            # æ£€æŸ¥å¹¶æ‰§è¡Œæ•°æ®åº“è¿ç§»
            if self.config_manager.get("migration_settings.auto_migrate", True):
                await self._check_and_migrate_database()

            # åˆå§‹åŒ–MemoryEngine
            stopwords_dir = os.path.join(self.data_dir, "stopwords")
            os.makedirs(stopwords_dir, exist_ok=True)

            memory_engine_config = {
                "rrf_k": self.config_manager.get("fusion_strategy.rrf_k", 60),
                "decay_rate": self.config_manager.get(
                    "importance_decay.decay_rate", 0.01
                ),
                "importance_weight": self.config_manager.get(
                    "recall_engine.importance_weight", 1.0
                ),
                "fallback_enabled": self.config_manager.get(
                    "recall_engine.fallback_to_vector", True
                ),
                "cleanup_days_threshold": self.config_manager.get(
                    "forgetting_agent.cleanup_days_threshold", 30
                ),
                "cleanup_importance_threshold": self.config_manager.get(
                    "forgetting_agent.cleanup_importance_threshold", 0.3
                ),
                "auto_cleanup_enabled": self.config_manager.get(
                    "forgetting_agent.auto_cleanup_enabled", True
                ),
                "stopwords_path": stopwords_dir,
            }

            self.memory_engine = MemoryEngine(
                db_path=db_path,
                faiss_db=self.db,
                llm_provider=self.llm_provider,
                config=memory_engine_config,
            )
            await self.memory_engine.initialize()
            logger.info("âœ… MemoryEngine å·²åˆå§‹åŒ–")

            # åˆå§‹åŒ– ConversationManager
            conversation_db_path = os.path.join(self.data_dir, "conversations.db")
            conversation_store = ConversationStore(conversation_db_path)
            await conversation_store.initialize()

            session_config = self.config_manager.session_manager
            self.conversation_manager = ConversationManager(
                store=conversation_store,
                max_cache_size=session_config.get("max_sessions", 100),
                context_window_size=session_config.get("context_window_size", 50),
                session_ttl=session_config.get("session_ttl", 3600),
            )
            logger.info("âœ… ConversationManager å·²åˆå§‹åŒ–")

            # è‡ªåŠ¨ä¿®å¤ message_count ä¸ä¸€è‡´é—®é¢˜
            await self._repair_message_counts(conversation_store)

            # åˆå§‹åŒ– MemoryProcessor
            if not self.llm_provider or not isinstance(self.llm_provider, Provider):
                raise ProviderNotReadyError("LLM Provider æœªåˆå§‹åŒ–æˆ–ç±»å‹ä¸æ­£ç¡®")
            self.memory_processor = MemoryProcessor(self.llm_provider, self.context)
            logger.info("âœ… MemoryProcessor å·²åˆå§‹åŒ–")

            # åˆå§‹åŒ–ç´¢å¼•éªŒè¯å™¨å¹¶è‡ªåŠ¨é‡å»ºç´¢å¼•
            self.index_validator = IndexValidator(db_path, self.db)
            await self._auto_rebuild_index_if_needed()

            # å¼‚æ­¥åˆå§‹åŒ– TextProcessor
            if self.memory_engine and hasattr(self.memory_engine, "text_processor"):
                if self.memory_engine.text_processor and hasattr(
                    self.memory_engine.text_processor, "async_init"
                ):
                    await self.memory_engine.text_processor.async_init()
                    logger.info("âœ… TextProcessor åœç”¨è¯å·²åŠ è½½")

            # å¯åŠ¨é‡è¦æ€§è¡°å‡è°ƒåº¦å™¨
            decay_rate = self.config_manager.get("importance_decay.decay_rate", 0.01)
            auto_cleanup_enabled = self.config_manager.get(
                "forgetting_agent.auto_cleanup_enabled", True
            )
            if self.memory_engine and (decay_rate > 0 or auto_cleanup_enabled):
                backup_enabled = self.config_manager.get("backup_settings.enabled", True)
                backup_keep_days = self.config_manager.get("backup_settings.keep_days", 7)
                scheduler = DecayScheduler(
                    memory_engine=self.memory_engine,
                    decay_rate=decay_rate,
                    data_dir=self.data_dir,
                    db_migration=self.db_migration,
                    backup_enabled=backup_enabled,
                    backup_keep_days=backup_keep_days,
                )
                await scheduler.start()
                self.decay_scheduler = scheduler
                logger.info("âœ… DecayScheduler å·²å¯åŠ¨")

            # æ ‡è®°åˆå§‹åŒ–å®Œæˆ
            self._initialization_complete = True
            logger.info("âœ… LivingMemory æ’ä»¶åˆå§‹åŒ–æˆåŠŸï¼")

        except Exception as e:
            logger.error(f"å®Œæ•´åˆå§‹åŒ–æµç¨‹å¤±è´¥: {e}", exc_info=True)
            self._initialization_failed = True
            self._initialization_error = str(e)
            raise InitializationError(f"åˆå§‹åŒ–å¤±è´¥: {e}") from e

    async def _check_and_migrate_database(self):
        """æ£€æŸ¥å¹¶æ‰§è¡Œæ•°æ®åº“è¿ç§»"""
        try:
            if not self.db_migration:
                logger.warning("æ•°æ®åº“è¿ç§»ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return

            needs_migration = await self.db_migration.needs_migration()

            if not needs_migration:
                logger.info("âœ… æ•°æ®åº“ç‰ˆæœ¬å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€è¿ç§»")
                return

            logger.info("ğŸ”„ æ£€æµ‹åˆ°æ—§ç‰ˆæœ¬æ•°æ®åº“ï¼Œå¼€å§‹è‡ªåŠ¨è¿ç§»...")

            if self.config_manager.get("migration_settings.create_backup", True):
                backup_path = await self.db_migration.create_backup()
                if backup_path:
                    logger.info(f"ğŸ’¾ æ•°æ®åº“å¤‡ä»½å·²åˆ›å»º: {backup_path}")

            result = await self.db_migration.migrate(
                sparse_retriever=None, progress_callback=None
            )

            if result.get("success"):
                logger.info(f"âœ… {result.get('message')}")
                logger.info(f"   è€—æ—¶: {result.get('duration', 0):.2f}ç§’")
            else:
                logger.error(f"âŒ æ•°æ®åº“è¿ç§»å¤±è´¥: {result.get('message')}")

        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿ç§»æ£€æŸ¥å¤±è´¥: {e}", exc_info=True)

    async def _auto_rebuild_index_if_needed(self):
        """è‡ªåŠ¨æ£€æŸ¥å¹¶é‡å»ºç´¢å¼•"""
        try:
            if not self.index_validator or not self.memory_engine:
                return

            # æ£€æŸ¥v1è¿ç§»çŠ¶æ€
            (
                needs_migration_rebuild,
                pending_count,
            ) = await self.index_validator.get_migration_status()

            if needs_migration_rebuild:
                logger.info(
                    f"ğŸ”„ æ£€æµ‹åˆ° v1 è¿ç§»æ•°æ®éœ€è¦é‡å»ºç´¢å¼•ï¼ˆ{pending_count} æ¡æ–‡æ¡£ï¼‰"
                )
                logger.info("ğŸ”¨ å¼€å§‹è‡ªåŠ¨é‡å»ºç´¢å¼•...")

                result = await self.index_validator.rebuild_indexes(self.memory_engine)

                if result["success"]:
                    logger.info(
                        f"âœ… ç´¢å¼•è‡ªåŠ¨é‡å»ºå®Œæˆ: æˆåŠŸ {result['processed']} æ¡, å¤±è´¥ {result['errors']} æ¡"
                    )
                else:
                    logger.error(f"âŒ ç´¢å¼•è‡ªåŠ¨é‡å»ºå¤±è´¥: {result.get('message')}")
                return

            # æ£€æŸ¥ç´¢å¼•ä¸€è‡´æ€§
            status = await self.index_validator.check_consistency()

            if not status.is_consistent and status.needs_rebuild:
                logger.warning(f"âš ï¸ æ£€æµ‹åˆ°ç´¢å¼•ä¸ä¸€è‡´: {status.reason}")
                logger.info(
                    f"ğŸ“Š Documents: {status.documents_count}, BM25: {status.bm25_count}, Vector: {status.vector_count}"
                )
                logger.info("ğŸ”¨ å¼€å§‹è‡ªåŠ¨é‡å»ºç´¢å¼•...")

                result = await self.index_validator.rebuild_indexes(self.memory_engine)

                if result["success"]:
                    logger.info(
                        f"âœ… ç´¢å¼•è‡ªåŠ¨é‡å»ºå®Œæˆ: æˆåŠŸ {result['processed']} æ¡, å¤±è´¥ {result['errors']} æ¡"
                    )
                else:
                    logger.error(f"âŒ ç´¢å¼•è‡ªåŠ¨é‡å»ºå¤±è´¥: {result.get('message')}")
            else:
                logger.info(f"âœ… ç´¢å¼•ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡: {status.reason}")

        except Exception as e:
            logger.error(f"è‡ªåŠ¨é‡å»ºç´¢å¼•å¤±è´¥: {e}", exc_info=True)

    async def _repair_message_counts(self, conversation_store: ConversationStore):
        """ä¿®å¤ä¼šè¯è¡¨ä¸­ message_count ä¸å®é™…æ¶ˆæ¯æ•°é‡ä¸ä¸€è‡´çš„é—®é¢˜"""
        try:
            logger.info("ğŸ” æ£€æŸ¥å¹¶ä¿®å¤ message_count ä¸€è‡´æ€§...")
            fixed_sessions = await conversation_store.sync_message_counts()

            if fixed_sessions:
                logger.info(f"âœ… å·²ä¿®å¤ {len(fixed_sessions)} ä¸ªä¼šè¯çš„ message_count")
            else:
                logger.debug("âœ… æ‰€æœ‰ä¼šè¯çš„ message_count å‡æ­£ç¡®")

        except Exception as e:
            logger.error(f"ä¿®å¤ message_count å¤±è´¥: {e}", exc_info=True)

    @property
    def is_initialized(self) -> bool:
        """æ˜¯å¦å·²åˆå§‹åŒ–"""
        return self._initialization_complete

    @property
    def is_failed(self) -> bool:
        """æ˜¯å¦åˆå§‹åŒ–å¤±è´¥"""
        return self._initialization_failed

    @property
    def error_message(self) -> str | None:
        """é”™è¯¯æ¶ˆæ¯"""
        return self._initialization_error

    async def ensure_initialized(self, timeout: float = 30.0) -> bool:
        """
        ç¡®ä¿æ’ä»¶å·²åˆå§‹åŒ–

        Args:
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            bool: æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        """
        if self._initialization_complete:
            return True

        if self._initialization_failed:
            return False

        # ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
        start_time = time.time()
        while not self._initialization_complete and not self._initialization_failed:
            if time.time() - start_time > timeout:
                logger.error(f"ç­‰å¾…æ’ä»¶åˆå§‹åŒ–è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
                return False
            await asyncio.sleep(0.2)

        return self._initialization_complete

    async def _check_and_fix_dimension_mismatch(self, index_path: str) -> None:
        """
        æ£€æŸ¥ FAISS ç´¢å¼•ç»´åº¦ä¸å½“å‰ embedding provider ç»´åº¦æ˜¯å¦ä¸€è‡´

        å½“ç”¨æˆ·æ›´æ¢ embedding provider åï¼Œæ—§ç´¢å¼•çš„ç»´åº¦å¯èƒ½ä¸æ–°æ¨¡å‹ä¸åŒ¹é…ï¼Œ
        å¯¼è‡´ FAISS æ’å…¥æ—¶æŠ¥é”™ "assert d == self.d"ã€‚
        æ­¤æ–¹æ³•æ£€æµ‹å¹¶è‡ªåŠ¨åˆ é™¤ä¸å…¼å®¹çš„æ—§ç´¢å¼•ï¼Œè®©ç³»ç»Ÿé‡å»ºã€‚

        Args:
            index_path: FAISS ç´¢å¼•æ–‡ä»¶è·¯å¾„
        """
        if not os.path.exists(index_path):
            return

        try:
            import faiss

            old_index = faiss.read_index(index_path)
            old_dim = old_index.d
            new_dim = self.embedding_provider.get_dim()  # type: ignore

            if old_dim != new_dim:
                logger.warning(
                    f"âš ï¸ æ£€æµ‹åˆ° FAISS ç´¢å¼•ç»´åº¦ä¸åŒ¹é…: ç´¢å¼•ç»´åº¦={old_dim}, "
                    f"å½“å‰ Embedding Provider ç»´åº¦={new_dim}"
                )
                logger.warning(
                    "è¿™é€šå¸¸æ˜¯å› ä¸ºæ›´æ¢äº† Embedding æ¨¡å‹å¯¼è‡´çš„ã€‚"
                    "æ—§ç´¢å¼•å°†è¢«åˆ é™¤ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é‡å»ºç´¢å¼•ã€‚"
                )

                os.remove(index_path)
                logger.info(f"âœ… å·²åˆ é™¤ä¸å…¼å®¹çš„æ—§ç´¢å¼•æ–‡ä»¶: {index_path}")
                logger.info("âš ï¸ æ³¨æ„: å‘é‡æ£€ç´¢åŠŸèƒ½å°†æš‚æ—¶ä¸å¯ç”¨ï¼Œç›´åˆ°é‡æ–°å¯¼å…¥è®°å¿†æ•°æ®ã€‚")

        except Exception as e:
            logger.error(f"æ£€æŸ¥ç´¢å¼•ç»´åº¦æ—¶å‡ºé”™: {e}", exc_info=True)

    async def stop_scheduler(self) -> None:
        """åœæ­¢è¡°å‡è°ƒåº¦å™¨"""
        if self.decay_scheduler:
            await self.decay_scheduler.stop()
            self.decay_scheduler = None

    async def stop_background_tasks(self) -> None:
        """åœæ­¢åˆå§‹åŒ–é˜¶æ®µçš„åå°ä»»åŠ¡ï¼ˆå¦‚Provideré‡è¯•ï¼‰"""
        if self._retry_task and not self._retry_task.done():
            self._retry_task.cancel()
            try:
                await self._retry_task
            except asyncio.CancelledError:
                pass
        self._retry_task = None
